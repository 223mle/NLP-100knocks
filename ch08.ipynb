{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsutsumi-ozro/NLP-100knocks/blob/main/ch08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKZ4e4BuuJTw"
      },
      "source": [
        "## 第8章: ニューラルネット\n",
        "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqUPMBWZuJTy"
      },
      "source": [
        "### 70. 単語ベクトルの和による特徴量\n",
        "※問題文に数式が多く含まれているため、記述しない。<br>\n",
        "[問題文](https://nlp100.github.io/ja/ch08.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "問題50と同じことをする(閲覧している解答が変わっているため若干コードにも変化はあるが、やっていることはほとんど同じ)"
      ],
      "metadata": {
        "id": "5IBIS26evtDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
        "!unzip /content/NewsAggregatorDataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLHWq5GBu0cX",
        "outputId": "8c285f77-b3e5-42f9-92b1-95ef5bed94a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-06 00:49:19--  https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29224203 (28M) [application/x-httpd-php]\n",
            "Saving to: ‘NewsAggregatorDataset.zip’\n",
            "\n",
            "NewsAggregatorDatas 100%[===================>]  27.87M  8.55MB/s    in 3.3s    \n",
            "\n",
            "2023-01-06 00:49:23 (8.55 MB/s) - ‘NewsAggregatorDataset.zip’ saved [29224203/29224203]\n",
            "\n",
            "Archive:  /content/NewsAggregatorDataset.zip\n",
            "  inflating: 2pageSessions.csv       \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._2pageSessions.csv  \n",
            "  inflating: newsCorpora.csv         \n",
            "  inflating: __MACOSX/._newsCorpora.csv  \n",
            "  inflating: readme.txt              \n",
            "  inflating: __MACOSX/._readme.txt   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "columns = ['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP']\n",
        "df = pd.read_csv('/content/newsCorpora.csv', header=None, sep='\\t', names=columns)\n",
        "\n",
        "df = df.loc[df['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']), ['TITLE', 'CATEGORY']]\n",
        "\n",
        "train, valid_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=123, stratify=df['CATEGORY'])\n",
        "valid, test = train_test_split(valid_test, test_size=0.5, shuffle=True, random_state=123, stratify=valid_test['CATEGORY'])"
      ],
      "metadata": {
        "id": "N8SLb1u-vaqL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "問題60で使用した学習済み単語ベクトルをダウンロード"
      ],
      "metadata": {
        "id": "7OWVQGAav3mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FILE_ID = \"0B7XkCwpI5KDYNlNUTTlSS21pQmM\"\n",
        "FILE_NAME = \"GoogleNews-vectors-negative300.bin.gz\"\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$FILE_ID\" -O $FILE_NAME && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdmUclVhv3H6",
        "outputId": "394fb403-4b3e-437d-b59b-1b6574715788"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-06 00:49:29--  https://docs.google.com/uc?export=download&confirm=&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "Resolving docs.google.com (docs.google.com)... 172.253.118.100, 172.253.118.138, 172.253.118.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.253.118.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0g-8s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7r2i97p4fbc04eff8t3suqpdhepoaplm/1672966125000/06848720943842814915/*/0B7XkCwpI5KDYNlNUTTlSS21pQmM?e=download&uuid=86b68c1f-48c7-438a-bc99-df1e9cafa123 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-01-06 00:49:29--  https://doc-0g-8s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7r2i97p4fbc04eff8t3suqpdhepoaplm/1672966125000/06848720943842814915/*/0B7XkCwpI5KDYNlNUTTlSS21pQmM?e=download&uuid=86b68c1f-48c7-438a-bc99-df1e9cafa123\n",
            "Resolving doc-0g-8s-docs.googleusercontent.com (doc-0g-8s-docs.googleusercontent.com)... 142.251.10.132, 2404:6800:4003:c0f::84\n",
            "Connecting to doc-0g-8s-docs.googleusercontent.com (doc-0g-8s-docs.googleusercontent.com)|142.251.10.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  84.1MB/s    in 23s     \n",
            "\n",
            "2023-01-06 00:49:53 (69.6 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format('/content/GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "metadata": {
        "id": "8gdNdSDowudO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "maketransはマッピングするのか<br>\n",
        "https://www.w3big.com/ja/python/att-string-maketrans.html<br>\n",
        "こちらstring<br>\n",
        "https://docs.python.org/ja/3/library/string.html<br>\n",
        "返り値はこれをしてる<br>\n",
        "\n",
        "$\\boldsymbol{x}_i = \\frac{1}{T_i} \\sum_{t=1}^{T_i} \\mathrm{emb}(w_{i,t})$\n"
      ],
      "metadata": {
        "id": "dx56Gxc3SU9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import torch\n",
        "\n",
        "def transform_w2v(text):\n",
        "    #!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~を空白に置換しようとしてるわけ\n",
        "    table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "    words = text.translate(table).split()\n",
        "    #ここでベクトル変換してる\n",
        "    vec = [model[word] for word in words if word in model]\n",
        "\n",
        "    return torch.tensor(sum(vec)/len(vec))"
      ],
      "metadata": {
        "id": "VxcaAy1lxgwA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.stack([transform_w2v(text) for text in train['TITLE']])\n",
        "X_valid = torch.stack([transform_w2v(text) for text in valid['TITLE']])\n",
        "X_test = torch.stack([transform_w2v(text) for text in test['TITLE']])"
      ],
      "metadata": {
        "id": "VJmMCly9UUB0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_dict = {'b':0, 't':1, 'e':2, 'm':3}\n",
        "y_train = torch.tensor(train['CATEGORY'].map(lambda x: category_dict[x]).values)\n",
        "y_valid = torch.tensor(valid['CATEGORY'].map(lambda x: category_dict[x]).values)\n",
        "y_test = torch.tensor(test['CATEGORY'].map(lambda x: category_dict[x]).values)"
      ],
      "metadata": {
        "id": "QN98GdulUvrx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(X_train, 'X_train.pt')\n",
        "torch.save(X_valid, 'X_valid.pt')\n",
        "torch.save(X_test, 'X_test.pt')\n",
        "torch.save(y_train, 'y_train.pt')\n",
        "torch.save(y_valid, 'y_valid.pt')\n",
        "torch.save(y_test, 'y_test.pt')"
      ],
      "metadata": {
        "id": "a6SEPYKbVPjE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3bnpbQjuJTy"
      },
      "source": [
        "### 71. 単層ニューラルネットワークによる予測\n",
        "※問題文に数式が含まれているため、記述しない。<br>\n",
        "[問題文](https://nlp100.github.io/ja/ch08.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=torch+nn+linear#torch.nn.Linear<br>\n",
        "https://pytorch.org/docs/stable/nn.init.html?highlight=nn+init+normal_#torch.nn.init.normal_<br>\n"
      ],
      "metadata": {
        "id": "T81tN57IvAlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class SLPNet(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(input_size, output_size, bias=False)\n",
        "        nn.init.normal_(self.fc.weight, 0.0, 1.0)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = SLPNet(300, 4)\n",
        "y_hat_1 = torch.softmax(model(X_train[:1]), dim=-1)\n",
        "print(y_hat_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAfvgeybu0wI",
        "outputId": "03de99db-09e4-4200-b9fb-e8e2339e24e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0519, 0.1082, 0.4951, 0.3448]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = torch.softmax(model(X_train[:4]), dim=-1)\n",
        "print(y_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg9MS8vluPiR",
        "outputId": "e16e7d45-8bd0-4195-ef89-b9fceb827f7f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0519, 0.1082, 0.4951, 0.3448],\n",
            "        [0.3120, 0.2216, 0.2360, 0.2304],\n",
            "        [0.0363, 0.1407, 0.6645, 0.1585],\n",
            "        [0.7013, 0.0281, 0.1155, 0.1551]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dld_kiFquJTy"
      },
      "source": [
        "### 72. 損失と勾配の計算\n",
        "※問題文に数式が含まれているため、記述しない。<br>\n",
        "[問題文](https://nlp100.github.io/ja/ch08.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss_x1 = loss_fn(model(X_train[:1]), y_train[:1])\n",
        "model.zero_grad()\n",
        "loss_x1.backward()\n",
        "print(f'損失: {loss_x1:.4f}')\n",
        "print(f'勾配: \\n{model.fc.weight.grad}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fMmUMgfvW5i",
        "outputId": "0166c47b-86b8-4892-8b9d-54b7b0536372"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "損失: 2.9576\n",
            "勾配: \n",
            "tensor([[ 0.0161, -0.1249,  0.0690,  ..., -0.0374, -0.0211, -0.0174],\n",
            "        [-0.0018,  0.0143, -0.0079,  ...,  0.0043,  0.0024,  0.0020],\n",
            "        [-0.0084,  0.0652, -0.0360,  ...,  0.0196,  0.0110,  0.0091],\n",
            "        [-0.0058,  0.0454, -0.0251,  ...,  0.0136,  0.0077,  0.0063]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_x1_to_x4 = loss_fn(model(X_train[:4]), y_train[:4])\n",
        "model.zero_grad()\n",
        "loss_x1_to_x4.backward()\n",
        "print(f'損失: {loss_x1_to_x4:.4f}')\n",
        "print(f'勾配: \\n{model.fc.weight.grad}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XRxSYc8wN5t",
        "outputId": "d2c0eff4-65f5-4a0f-d8c4-0617b7d8070f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "損失: 1.9482\n",
            "勾配: \n",
            "tensor([[ 0.0407, -0.0279,  0.0351,  ..., -0.0083, -0.0259, -0.0069],\n",
            "        [-0.0091,  0.0009, -0.0076,  ...,  0.0019,  0.0029, -0.0004],\n",
            "        [-0.0201,  0.0137, -0.0152,  ...,  0.0022,  0.0186,  0.0065],\n",
            "        [-0.0115,  0.0132, -0.0123,  ...,  0.0042,  0.0043,  0.0009]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3omp-e_uJTy"
      },
      "source": [
        "### 73.  確率的勾配降下法による学習\n",
        "確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，行列Wを学習せよ．なお，学習は適当な基準で終了させればよい（例えば「100エポックで終了」など）．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return [self.X[index], self.y[index]]\n",
        "\n",
        "dataset_train = NewsDataset(X_train, y_train)\n",
        "dataset_valid = NewsDataset(X_valid, y_valid)\n",
        "dataset_test = NewsDataset(X_test, y_test)\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=32, shuffle=False)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "To0XP7N8wh38"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.loss import CrossEntropyLoss\n",
        "\n",
        "model = SLPNet(300, 4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    loss_train = 0.0\n",
        "    for i, (inputs, labels) in enumerate(dataloader_train):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_train += loss.item()\n",
        "    \n",
        "    loss_train = loss_train / i\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs, labels = next(iter(dataloader_valid))\n",
        "        outputs = model(inputs)\n",
        "        loss_valid = loss_fn(outputs, labels)\n",
        "    if (epoch+1)%10==0:\n",
        "        print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, loss_valid: {loss_valid:.4f}')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fDtM2naxdYf",
        "outputId": "aca29225-e223-4625-9e9a-2f9e5dd42ea3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss_train: 0.5744, loss_valid: 0.5919\n",
            "epoch: 20, loss_train: 0.4572, loss_valid: 0.4878\n",
            "epoch: 30, loss_train: 0.4055, loss_valid: 0.4454\n",
            "epoch: 40, loss_train: 0.3752, loss_valid: 0.4178\n",
            "epoch: 50, loss_train: 0.3545, loss_valid: 0.4022\n",
            "epoch: 60, loss_train: 0.3397, loss_valid: 0.3917\n",
            "epoch: 70, loss_train: 0.3281, loss_valid: 0.3840\n",
            "epoch: 80, loss_train: 0.3187, loss_valid: 0.3790\n",
            "epoch: 90, loss_train: 0.3110, loss_valid: 0.3740\n",
            "epoch: 100, loss_train: 0.3043, loss_valid: 0.3702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_G_7T__uJTz"
      },
      "source": [
        "### 74. 正解率の計測\n",
        "問題73で求めた行列を用いて学習データおよび評価データの事例を分類したとき，その正解率をそれぞれ求めよ．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            outputs = model(inputs)\n",
        "            pred = torch.argmax(outputs, dim=-1)\n",
        "            total += len(inputs)\n",
        "            #sum? 0 or 1の出力だと思ってたけども.\n",
        "            # argmaxのdocumentを読んで理解\n",
        "            # https://pytorch.org/docs/stable/generated/torch.argmax.html?highlight=torch+argmax#torch.argmax\n",
        "            correct += (pred==labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "acc_train = calculate_accuracy(model, dataloader_train)\n",
        "acc_test = calculate_accuracy(model, dataloader_test)\n",
        "print(f'train accuracy score: {acc_train:.3f}')\n",
        "print(f'test accuracy score：{acc_test:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX5v3iiZ1syt",
        "outputId": "01ede81c-e37d-4948-de48-20e03ed73b7b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train accuracy score: 0.894\n",
            "test accuracy score：0.889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKfMCvqAuJTz"
      },
      "source": [
        "### 75. 損失と正解率のプロット\n",
        "問題73のコードを改変し，各エポックのパラメータ更新が完了するたびに，訓練データでの損失，正解率，検証データでの損失，正解率をグラフにプロットし，学習の進捗状況を確認できるようにせよ．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss_and_accuracy(model, loss_fn, loader):\n",
        "    model.eval()\n",
        "    loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            outputs = model(inputs)\n",
        "            loss += loss_fn(outputs, labels)\n",
        "            pred = torch.argmax(outputs, dim=-1)\n",
        "            total += len(inputs)\n",
        "            correct += (pred==labels).sum().item()\n",
        "    return loss/len(loader), correct/total"
      ],
      "metadata": {
        "id": "umJaHDBf3po6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SLPNet(300, 4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "\n",
        "num_epochs = 100\n",
        "log_train = []\n",
        "log_valid = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in dataloader_train:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    loss_train, acc_train = calculate_loss_and_accuracy(model, loss_fn, dataloader_train)\n",
        "    loss_valid, acc_valid = calculate_loss_and_accuracy(model, loss_fn, dataloader_valid)\n",
        "    log_train.append([loss_train, acc_train])\n",
        "    log_valid.append([loss_valid, acc_valid])\n",
        "\n",
        "    if (epoch+1)%10==0:\n",
        "        print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTm5VYXW4XH-",
        "outputId": "df099d67-a4ca-4954-dba6-c034f881782d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss_train: 0.5698, accuracy_train: 0.7939, loss_valid: 0.6075, accuracy_valid: 0.7729\n",
            "epoch: 20, loss_train: 0.4556, accuracy_train: 0.8369, loss_valid: 0.4891, accuracy_valid: 0.8328\n",
            "epoch: 30, loss_train: 0.4042, accuracy_train: 0.8559, loss_valid: 0.4353, accuracy_valid: 0.8546\n",
            "epoch: 40, loss_train: 0.3738, accuracy_train: 0.8663, loss_valid: 0.4039, accuracy_valid: 0.8621\n",
            "epoch: 50, loss_train: 0.3539, accuracy_train: 0.8748, loss_valid: 0.3828, accuracy_valid: 0.8673\n",
            "epoch: 60, loss_train: 0.3390, accuracy_train: 0.8808, loss_valid: 0.3675, accuracy_valid: 0.8733\n",
            "epoch: 70, loss_train: 0.3278, accuracy_train: 0.8853, loss_valid: 0.3558, accuracy_valid: 0.8778\n",
            "epoch: 80, loss_train: 0.3183, accuracy_train: 0.8884, loss_valid: 0.3464, accuracy_valid: 0.8831\n",
            "epoch: 90, loss_train: 0.3110, accuracy_train: 0.8923, loss_valid: 0.3387, accuracy_valid: 0.8846\n",
            "epoch: 100, loss_train: 0.3047, accuracy_train: 0.8943, loss_valid: 0.3321, accuracy_valid: 0.8876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "ax[0].plot(np.array(log_train).T[0], label='train', color='blue')\n",
        "ax[0].plot(np.array(log_valid).T[0], label='valid', color='red')\n",
        "ax[0].set_xlabel('epoch')\n",
        "ax[0].set_ylabel('loss')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(np.array(log_train).T[1], label='train', color='blue')\n",
        "ax[1].plot(np.array(log_valid).T[1], label='valid', color='red')\n",
        "ax[1].set_xlabel('epoch')\n",
        "ax[1].set_ylabel('accuracy')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "UIAWmYlZ5t5L",
        "outputId": "6d281a9c-1cee-46fa-9f39-72891ede9f95"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZuFBUmDuJTz"
      },
      "source": [
        "### 76. チェックポイント\n",
        "問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SLPNet(300, 4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "\n",
        "num_epochs = 100\n",
        "log_train = []\n",
        "log_valid = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in dataloader_train:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    loss_train, acc_train = calculate_loss_and_accuracy(model, loss_fn, dataloader_train)\n",
        "    loss_valid, acc_valid = calculate_loss_and_accuracy(model, loss_fn, dataloader_valid)\n",
        "    log_train.append([loss_train, acc_train])\n",
        "    log_valid.append([loss_valid, acc_valid])\n",
        "\n",
        "    torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch+1}.pt')\n",
        "    if (epoch+1)%10==0:\n",
        "        print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV8VJ1ckfQGA",
        "outputId": "eb0b4e8d-c83d-45a8-c9db-3dcd7151eabf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss_train: 0.5665, accuracy_train: 0.7927, loss_valid: 0.5958, accuracy_valid: 0.8013\n",
            "epoch: 20, loss_train: 0.4559, accuracy_train: 0.8323, loss_valid: 0.4877, accuracy_valid: 0.8313\n",
            "epoch: 30, loss_train: 0.4056, accuracy_train: 0.8541, loss_valid: 0.4382, accuracy_valid: 0.8508\n",
            "epoch: 40, loss_train: 0.3754, accuracy_train: 0.8665, loss_valid: 0.4087, accuracy_valid: 0.8583\n",
            "epoch: 50, loss_train: 0.3552, accuracy_train: 0.8743, loss_valid: 0.3887, accuracy_valid: 0.8673\n",
            "epoch: 60, loss_train: 0.3404, accuracy_train: 0.8796, loss_valid: 0.3741, accuracy_valid: 0.8688\n",
            "epoch: 70, loss_train: 0.3293, accuracy_train: 0.8845, loss_valid: 0.3628, accuracy_valid: 0.8718\n",
            "epoch: 80, loss_train: 0.3201, accuracy_train: 0.8878, loss_valid: 0.3538, accuracy_valid: 0.8748\n",
            "epoch: 90, loss_train: 0.3124, accuracy_train: 0.8912, loss_valid: 0.3463, accuracy_valid: 0.8778\n",
            "epoch: 100, loss_train: 0.3060, accuracy_train: 0.8937, loss_valid: 0.3400, accuracy_valid: 0.8786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZoIIlTHuJTz"
      },
      "source": [
        "### 77. ミニバッチ化\n",
        "問題76のコードを改変し，B事例ごとに損失・勾配を計算し，行列Wの値を更新せよ（ミニバッチ化）．Bの値を1,2,4,8,…と変化させながら，1エポックの学習に要する時間を比較せよ．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def train_model(datset_train, datset_valid, batch_size, model, loss_fn, optimizer, num_epochs):\n",
        "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "    dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    log_train = []\n",
        "    log_valid = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        s_time = time.time()\n",
        "        model.train()\n",
        "        for inputs, labels in dataloader_train:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        loss_trian, acc_train = calculate_loss_and_accuracy(model, loss_fn, dataloader_train)\n",
        "        loss_valid, acc_valid = calculate_loss_and_accuracy(model, loss_fn, dataloader_valid)\n",
        "        log_train.append([loss_train, acc_train])\n",
        "        log_valid.append([loss_valid, acc_valid])\n",
        "\n",
        "        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch+1}.pt')\n",
        "\n",
        "        e_time = time.time()\n",
        "        #if (epoch+1)%10==0:\n",
        "        print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}, {(e_time - s_time):.4f}sec') \n",
        "\n",
        "    return {'train': log_train, 'valid': log_valid}"
      ],
      "metadata": {
        "id": "9DlV0pyJfylk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = [2**n for n in range(1, 6)]\n",
        "\n",
        "dataset_train = NewsDataset(X_train, y_train)\n",
        "dataset_valid = NewsDataset(X_valid, y_valid)\n",
        "\n",
        "for batch_size in b:\n",
        "    num_epoch = 1\n",
        "    print(f'バッチサイズ: {batch_size}')\n",
        "    log = train_model(dataset_train, dataset_valid, batch_size, model, loss_fn, optimizer, num_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9EBkHkMhOCW",
        "outputId": "965f108e-e159-4f47-d393-8b4b16b0d567"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "バッチサイズ: 2\n",
            "epoch: 1, loss_train: 0.3060, accuracy_train: 0.8990, loss_valid: 0.3271, accuracy_valid: 0.8846, 2.1223sec\n",
            "バッチサイズ: 4\n",
            "epoch: 1, loss_train: 0.3060, accuracy_train: 0.9017, loss_valid: 0.3219, accuracy_valid: 0.8891, 1.1606sec\n",
            "バッチサイズ: 8\n",
            "epoch: 1, loss_train: 0.3060, accuracy_train: 0.9014, loss_valid: 0.3173, accuracy_valid: 0.8883, 0.6154sec\n",
            "バッチサイズ: 16\n",
            "epoch: 1, loss_train: 0.3060, accuracy_train: 0.9023, loss_valid: 0.3159, accuracy_valid: 0.8913, 0.3772sec\n",
            "バッチサイズ: 32\n",
            "epoch: 1, loss_train: 0.3060, accuracy_train: 0.9022, loss_valid: 0.3194, accuracy_valid: 0.8891, 0.2404sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Q5LSgvuJTz"
      },
      "source": [
        "### 78. GPU上での学習\n",
        "問題77のコードを改変し，GPU上で学習を実行せよ．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#以前作成した関数にdeviceを追加\n",
        "\n",
        "def calculate_loss_and_accuracy(model, loss_fn, loader, device):\n",
        "  model.eval()\n",
        "  loss = 0.0\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in loader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss += loss_fn(outputs, labels).item()\n",
        "      pred = torch.argmax(outputs, dim=-1)\n",
        "      total += len(inputs)\n",
        "      correct += (pred == labels).sum().item()\n",
        "      \n",
        "  return loss / len(loader), correct / total\n",
        "\n",
        "def train_model(datset_train, datset_valid, batch_size, model, loss_fn, optimizer, num_epochs, device=None):\n",
        "    model.to(device)\n",
        "    \n",
        "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "    dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    log_train = []\n",
        "    log_valid = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        s_time = time.time()\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for inputs, labels in dataloader_train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model.forward(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        loss_trian, acc_train = calculate_loss_and_accuracy(model, loss_fn, dataloader_train, device)\n",
        "        loss_valid, acc_valid = calculate_loss_and_accuracy(model, loss_fn, dataloader_valid, device)\n",
        "        log_train.append([loss_train, acc_train])\n",
        "        log_valid.append([loss_valid, acc_valid])\n",
        "\n",
        "        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch+1}.pt')\n",
        "\n",
        "        e_time = time.time()\n",
        "        #if (epoch+1)%10==0:\n",
        "        print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}, {(e_time - s_time):.4f}sec') \n",
        "\n",
        "    return {'train': log_train, 'valid': log_valid}"
      ],
      "metadata": {
        "id": "zlM9p33_jUvf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = SLPNet(300, 4)\n",
        "for batch_size in b:\n",
        "    num_epoch = 1\n",
        "    print(f'バッチサイズ: {batch_size}')\n",
        "    log = train_model(dataset_train, dataset_valid, batch_size, model, loss_fn, optimizer, num_epoch, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjJQSrqdj-S5",
        "outputId": "feb37452-bc72-4153-cd4f-a19ced6f899e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "バッチサイズ: 2\n",
            "epoch: 1, loss_train: 0.3060, accuracy_train: 0.2013, loss_valid: 2.6435, accuracy_valid: 0.2009, 5.0048sec\n",
            "バッチサイズ: 4\n",
            "epoch: 1, loss_train: 0.3060, accuracy_train: 0.2013, loss_valid: 2.6442, accuracy_valid: 0.2009, 2.5115sec\n",
            "バッチサイズ: 8\n",
            "epoch: 1, loss_train: 0.3060, accuracy_train: 0.2013, loss_valid: 2.6431, accuracy_valid: 0.2009, 1.3639sec\n",
            "バッチサイズ: 16\n",
            "epoch: 1, loss_train: 0.3060, accuracy_train: 0.2013, loss_valid: 2.6444, accuracy_valid: 0.2009, 0.7108sec\n",
            "バッチサイズ: 32\n",
            "epoch: 1, loss_train: 0.3060, accuracy_train: 0.2013, loss_valid: 2.6451, accuracy_valid: 0.2009, 0.4320sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbKEeSC-uJTz"
      },
      "source": [
        "### 79. 多層ニューラルネットワーク\n",
        "問題78のコードを改変し，バイアス項の導入や多層化など，ニューラルネットワークの形状を変更しながら，高性能なカテゴリ分類器を構築せよ．"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html<br>\n",
        "https://smile-jsp.hateblo.jp/entry/2020/06/23/001147"
      ],
      "metadata": {
        "id": "vMjuRKq-n85t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "S33FMzNZuJTz"
      },
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "class MLPNet(nn.Module):\n",
        "    def __init__(self, input_size, mid_size, output_size, mid_layers):\n",
        "        super().__init__()\n",
        "        self.mid_layers = mid_layers\n",
        "        self.fc = nn.Linear(input_size, mid_size)\n",
        "        self.fc_mid = nn.Linear(mid_size, mid_size)\n",
        "        self.fc_out = nn.Linear(mid_size, output_size)\n",
        "        self.bn = nn.BatchNorm1d(mid_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc(x))\n",
        "        for _ in range(self.mid_layers):\n",
        "            x = F.relu(self.bn(self.fc_mid(x)))\n",
        "        x = F.relu(self.fc_out(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "\n",
        "def train_model(datset_train, datset_valid, batch_size, model, loss_fn, optimizer, num_epochs, device=None):\n",
        "    model.to(device)\n",
        "    \n",
        "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "    dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    #スケジューラの設定を行う\n",
        "    #https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs, eta_min=1e-5, last_epoch=-1)\n",
        "\n",
        "    log_train = []\n",
        "    log_valid = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        s_time = time.time()\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for inputs, labels in dataloader_train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model.forward(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        loss_trian, acc_train = calculate_loss_and_accuracy(model, loss_fn, dataloader_train, device)\n",
        "        loss_valid, acc_valid = calculate_loss_and_accuracy(model, loss_fn, dataloader_valid, device)\n",
        "        log_train.append([loss_train, acc_train])\n",
        "        log_valid.append([loss_valid, acc_valid])\n",
        "\n",
        "        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch+1}.pt')\n",
        "\n",
        "        e_time = time.time()\n",
        "        #if (epoch+1)%10==0:\n",
        "        print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}, {(e_time - s_time):.4f}sec') \n",
        "\n",
        "        if epoch > 3 and log_valid[epoch-3][0]  <= log_valid[epoch-2][0] <= log_valid[epoch-1][0]<= log_valid[epoch][0]:\n",
        "            break\n",
        "        \n",
        "        scheduler.step()\n",
        "    return {'train': log_train, 'valid': log_valid}"
      ],
      "metadata": {
        "id": "0ehQKcAQo612"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = NewsDataset(X_train, y_train)\n",
        "dataset_valid = NewsDataset(X_valid, y_valid)\n",
        "\n",
        "model = MLPNet(300, 200, 4, 1)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "log = train_model(dataset_train, dataset_valid, 64, model, loss_fn, optimizer, 1000, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmbCdAsSqQfp",
        "outputId": "6ec4c955-5791-48f5-a978-f57887ba2009"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss_train: 0.3060, accuracy_train: 0.7463, loss_valid: 0.9865, accuracy_valid: 0.7361, 0.4264sec\n",
            "epoch: 2, loss_train: 0.3060, accuracy_train: 0.7759, loss_valid: 0.7490, accuracy_valid: 0.7751, 0.4365sec\n",
            "epoch: 3, loss_train: 0.3060, accuracy_train: 0.7824, loss_valid: 0.6688, accuracy_valid: 0.7804, 0.4342sec\n",
            "epoch: 4, loss_train: 0.3060, accuracy_train: 0.7884, loss_valid: 0.6257, accuracy_valid: 0.7849, 0.4435sec\n",
            "epoch: 5, loss_train: 0.3060, accuracy_train: 0.7987, loss_valid: 0.5905, accuracy_valid: 0.7991, 0.4263sec\n",
            "epoch: 6, loss_train: 0.3060, accuracy_train: 0.8112, loss_valid: 0.5587, accuracy_valid: 0.8088, 0.4502sec\n",
            "epoch: 7, loss_train: 0.3060, accuracy_train: 0.8195, loss_valid: 0.5301, accuracy_valid: 0.8178, 0.4498sec\n",
            "epoch: 8, loss_train: 0.3060, accuracy_train: 0.8337, loss_valid: 0.5028, accuracy_valid: 0.8328, 0.4398sec\n",
            "epoch: 9, loss_train: 0.3060, accuracy_train: 0.8428, loss_valid: 0.4813, accuracy_valid: 0.8448, 0.4401sec\n",
            "epoch: 10, loss_train: 0.3060, accuracy_train: 0.8579, loss_valid: 0.4628, accuracy_valid: 0.8606, 0.4329sec\n",
            "epoch: 11, loss_train: 0.3060, accuracy_train: 0.8646, loss_valid: 0.4468, accuracy_valid: 0.8636, 0.4438sec\n",
            "epoch: 12, loss_train: 0.3060, accuracy_train: 0.8685, loss_valid: 0.4300, accuracy_valid: 0.8643, 0.4331sec\n",
            "epoch: 13, loss_train: 0.3060, accuracy_train: 0.8772, loss_valid: 0.4184, accuracy_valid: 0.8681, 0.4427sec\n",
            "epoch: 14, loss_train: 0.3060, accuracy_train: 0.8780, loss_valid: 0.4059, accuracy_valid: 0.8696, 0.6203sec\n",
            "epoch: 15, loss_train: 0.3060, accuracy_train: 0.8835, loss_valid: 0.3958, accuracy_valid: 0.8718, 0.4972sec\n",
            "epoch: 16, loss_train: 0.3060, accuracy_train: 0.8846, loss_valid: 0.3848, accuracy_valid: 0.8718, 0.4395sec\n",
            "epoch: 17, loss_train: 0.3060, accuracy_train: 0.8876, loss_valid: 0.3770, accuracy_valid: 0.8741, 0.4616sec\n",
            "epoch: 18, loss_train: 0.3060, accuracy_train: 0.8891, loss_valid: 0.3677, accuracy_valid: 0.8771, 0.4330sec\n",
            "epoch: 19, loss_train: 0.3060, accuracy_train: 0.8916, loss_valid: 0.3613, accuracy_valid: 0.8771, 0.4345sec\n",
            "epoch: 20, loss_train: 0.3060, accuracy_train: 0.8931, loss_valid: 0.3565, accuracy_valid: 0.8816, 0.4417sec\n",
            "epoch: 21, loss_train: 0.3060, accuracy_train: 0.8953, loss_valid: 0.3504, accuracy_valid: 0.8838, 0.4741sec\n",
            "epoch: 22, loss_train: 0.3060, accuracy_train: 0.8959, loss_valid: 0.3445, accuracy_valid: 0.8853, 0.4455sec\n",
            "epoch: 23, loss_train: 0.3060, accuracy_train: 0.8972, loss_valid: 0.3407, accuracy_valid: 0.8906, 0.4269sec\n",
            "epoch: 24, loss_train: 0.3060, accuracy_train: 0.8996, loss_valid: 0.3363, accuracy_valid: 0.8928, 0.4442sec\n",
            "epoch: 25, loss_train: 0.3060, accuracy_train: 0.9009, loss_valid: 0.3311, accuracy_valid: 0.8928, 0.4289sec\n",
            "epoch: 26, loss_train: 0.3060, accuracy_train: 0.9016, loss_valid: 0.3276, accuracy_valid: 0.8928, 0.4463sec\n",
            "epoch: 27, loss_train: 0.3060, accuracy_train: 0.9020, loss_valid: 0.3267, accuracy_valid: 0.8906, 0.4351sec\n",
            "epoch: 28, loss_train: 0.3060, accuracy_train: 0.9041, loss_valid: 0.3236, accuracy_valid: 0.8936, 0.4362sec\n",
            "epoch: 29, loss_train: 0.3060, accuracy_train: 0.9053, loss_valid: 0.3188, accuracy_valid: 0.9010, 0.4398sec\n",
            "epoch: 30, loss_train: 0.3060, accuracy_train: 0.9064, loss_valid: 0.3173, accuracy_valid: 0.8958, 0.4264sec\n",
            "epoch: 31, loss_train: 0.3060, accuracy_train: 0.9073, loss_valid: 0.3124, accuracy_valid: 0.9003, 0.4453sec\n",
            "epoch: 32, loss_train: 0.3060, accuracy_train: 0.9089, loss_valid: 0.3113, accuracy_valid: 0.8981, 0.4493sec\n",
            "epoch: 33, loss_train: 0.3060, accuracy_train: 0.9109, loss_valid: 0.3081, accuracy_valid: 0.8988, 0.4405sec\n",
            "epoch: 34, loss_train: 0.3060, accuracy_train: 0.9102, loss_valid: 0.3058, accuracy_valid: 0.8966, 0.4528sec\n",
            "epoch: 35, loss_train: 0.3060, accuracy_train: 0.9120, loss_valid: 0.3026, accuracy_valid: 0.9025, 0.4447sec\n",
            "epoch: 36, loss_train: 0.3060, accuracy_train: 0.9136, loss_valid: 0.3005, accuracy_valid: 0.9025, 0.4336sec\n",
            "epoch: 37, loss_train: 0.3060, accuracy_train: 0.9131, loss_valid: 0.3010, accuracy_valid: 0.8973, 0.4385sec\n",
            "epoch: 38, loss_train: 0.3060, accuracy_train: 0.9148, loss_valid: 0.2972, accuracy_valid: 0.9025, 0.4663sec\n",
            "epoch: 39, loss_train: 0.3060, accuracy_train: 0.9133, loss_valid: 0.2948, accuracy_valid: 0.9018, 0.4395sec\n",
            "epoch: 40, loss_train: 0.3060, accuracy_train: 0.9157, loss_valid: 0.2947, accuracy_valid: 0.9003, 0.4416sec\n",
            "epoch: 41, loss_train: 0.3060, accuracy_train: 0.9171, loss_valid: 0.2930, accuracy_valid: 0.9033, 0.4324sec\n",
            "epoch: 42, loss_train: 0.3060, accuracy_train: 0.9176, loss_valid: 0.2913, accuracy_valid: 0.9078, 0.4378sec\n",
            "epoch: 43, loss_train: 0.3060, accuracy_train: 0.9182, loss_valid: 0.2890, accuracy_valid: 0.9070, 0.4345sec\n",
            "epoch: 44, loss_train: 0.3060, accuracy_train: 0.9192, loss_valid: 0.2873, accuracy_valid: 0.9063, 0.4454sec\n",
            "epoch: 45, loss_train: 0.3060, accuracy_train: 0.9204, loss_valid: 0.2880, accuracy_valid: 0.9055, 0.4384sec\n",
            "epoch: 46, loss_train: 0.3060, accuracy_train: 0.9198, loss_valid: 0.2847, accuracy_valid: 0.9055, 0.4413sec\n",
            "epoch: 47, loss_train: 0.3060, accuracy_train: 0.9210, loss_valid: 0.2837, accuracy_valid: 0.9063, 0.4278sec\n",
            "epoch: 48, loss_train: 0.3060, accuracy_train: 0.9217, loss_valid: 0.2823, accuracy_valid: 0.9048, 0.4337sec\n",
            "epoch: 49, loss_train: 0.3060, accuracy_train: 0.9233, loss_valid: 0.2812, accuracy_valid: 0.9070, 0.4354sec\n",
            "epoch: 50, loss_train: 0.3060, accuracy_train: 0.9236, loss_valid: 0.2796, accuracy_valid: 0.9078, 0.4454sec\n",
            "epoch: 51, loss_train: 0.3060, accuracy_train: 0.9223, loss_valid: 0.2783, accuracy_valid: 0.9078, 0.4345sec\n",
            "epoch: 52, loss_train: 0.3060, accuracy_train: 0.9245, loss_valid: 0.2790, accuracy_valid: 0.9048, 0.4322sec\n",
            "epoch: 53, loss_train: 0.3060, accuracy_train: 0.9255, loss_valid: 0.2755, accuracy_valid: 0.9108, 0.4485sec\n",
            "epoch: 54, loss_train: 0.3060, accuracy_train: 0.9268, loss_valid: 0.2761, accuracy_valid: 0.9108, 0.4324sec\n",
            "epoch: 55, loss_train: 0.3060, accuracy_train: 0.9256, loss_valid: 0.2759, accuracy_valid: 0.9055, 0.4358sec\n",
            "epoch: 56, loss_train: 0.3060, accuracy_train: 0.9269, loss_valid: 0.2746, accuracy_valid: 0.9070, 0.4305sec\n",
            "epoch: 57, loss_train: 0.3060, accuracy_train: 0.9280, loss_valid: 0.2722, accuracy_valid: 0.9055, 0.4485sec\n",
            "epoch: 58, loss_train: 0.3060, accuracy_train: 0.9291, loss_valid: 0.2706, accuracy_valid: 0.9063, 0.4431sec\n",
            "epoch: 59, loss_train: 0.3060, accuracy_train: 0.9287, loss_valid: 0.2711, accuracy_valid: 0.9085, 0.4610sec\n",
            "epoch: 60, loss_train: 0.3060, accuracy_train: 0.9293, loss_valid: 0.2697, accuracy_valid: 0.9093, 0.4498sec\n",
            "epoch: 61, loss_train: 0.3060, accuracy_train: 0.9304, loss_valid: 0.2671, accuracy_valid: 0.9100, 0.4547sec\n",
            "epoch: 62, loss_train: 0.3060, accuracy_train: 0.9305, loss_valid: 0.2676, accuracy_valid: 0.9078, 0.4878sec\n",
            "epoch: 63, loss_train: 0.3060, accuracy_train: 0.9313, loss_valid: 0.2669, accuracy_valid: 0.9085, 0.4384sec\n",
            "epoch: 64, loss_train: 0.3060, accuracy_train: 0.9318, loss_valid: 0.2668, accuracy_valid: 0.9085, 0.4522sec\n",
            "epoch: 65, loss_train: 0.3060, accuracy_train: 0.9323, loss_valid: 0.2643, accuracy_valid: 0.9100, 0.4294sec\n",
            "epoch: 66, loss_train: 0.3060, accuracy_train: 0.9332, loss_valid: 0.2643, accuracy_valid: 0.9078, 0.4451sec\n",
            "epoch: 67, loss_train: 0.3060, accuracy_train: 0.9338, loss_valid: 0.2639, accuracy_valid: 0.9093, 0.4318sec\n",
            "epoch: 68, loss_train: 0.3060, accuracy_train: 0.9328, loss_valid: 0.2651, accuracy_valid: 0.9078, 0.4434sec\n",
            "epoch: 69, loss_train: 0.3060, accuracy_train: 0.9345, loss_valid: 0.2643, accuracy_valid: 0.9085, 0.4374sec\n",
            "epoch: 70, loss_train: 0.3060, accuracy_train: 0.9334, loss_valid: 0.2622, accuracy_valid: 0.9108, 0.4477sec\n",
            "epoch: 71, loss_train: 0.3060, accuracy_train: 0.9348, loss_valid: 0.2607, accuracy_valid: 0.9100, 0.4306sec\n",
            "epoch: 72, loss_train: 0.3060, accuracy_train: 0.9355, loss_valid: 0.2604, accuracy_valid: 0.9093, 0.4305sec\n",
            "epoch: 73, loss_train: 0.3060, accuracy_train: 0.9364, loss_valid: 0.2609, accuracy_valid: 0.9070, 0.4469sec\n",
            "epoch: 74, loss_train: 0.3060, accuracy_train: 0.9364, loss_valid: 0.2588, accuracy_valid: 0.9130, 0.4332sec\n",
            "epoch: 75, loss_train: 0.3060, accuracy_train: 0.9368, loss_valid: 0.2578, accuracy_valid: 0.9115, 0.4369sec\n",
            "epoch: 76, loss_train: 0.3060, accuracy_train: 0.9365, loss_valid: 0.2592, accuracy_valid: 0.9123, 0.4407sec\n",
            "epoch: 77, loss_train: 0.3060, accuracy_train: 0.9375, loss_valid: 0.2583, accuracy_valid: 0.9100, 0.4462sec\n",
            "epoch: 78, loss_train: 0.3060, accuracy_train: 0.9378, loss_valid: 0.2572, accuracy_valid: 0.9085, 0.4341sec\n",
            "epoch: 79, loss_train: 0.3060, accuracy_train: 0.9387, loss_valid: 0.2569, accuracy_valid: 0.9093, 0.4332sec\n",
            "epoch: 80, loss_train: 0.3060, accuracy_train: 0.9387, loss_valid: 0.2563, accuracy_valid: 0.9123, 0.4468sec\n",
            "epoch: 81, loss_train: 0.3060, accuracy_train: 0.9394, loss_valid: 0.2564, accuracy_valid: 0.9070, 0.4458sec\n",
            "epoch: 82, loss_train: 0.3060, accuracy_train: 0.9399, loss_valid: 0.2544, accuracy_valid: 0.9115, 0.4414sec\n",
            "epoch: 83, loss_train: 0.3060, accuracy_train: 0.9412, loss_valid: 0.2562, accuracy_valid: 0.9033, 0.4406sec\n",
            "epoch: 84, loss_train: 0.3060, accuracy_train: 0.9412, loss_valid: 0.2550, accuracy_valid: 0.9108, 0.4525sec\n",
            "epoch: 85, loss_train: 0.3060, accuracy_train: 0.9412, loss_valid: 0.2566, accuracy_valid: 0.9040, 0.4691sec\n",
            "epoch: 86, loss_train: 0.3060, accuracy_train: 0.9405, loss_valid: 0.2557, accuracy_valid: 0.9108, 0.4495sec\n",
            "epoch: 87, loss_train: 0.3060, accuracy_train: 0.9436, loss_valid: 0.2541, accuracy_valid: 0.9055, 0.4522sec\n",
            "epoch: 88, loss_train: 0.3060, accuracy_train: 0.9442, loss_valid: 0.2532, accuracy_valid: 0.9093, 0.4335sec\n",
            "epoch: 89, loss_train: 0.3060, accuracy_train: 0.9426, loss_valid: 0.2546, accuracy_valid: 0.9070, 0.4488sec\n",
            "epoch: 90, loss_train: 0.3060, accuracy_train: 0.9435, loss_valid: 0.2551, accuracy_valid: 0.9040, 0.4335sec\n",
            "epoch: 91, loss_train: 0.3060, accuracy_train: 0.9448, loss_valid: 0.2512, accuracy_valid: 0.9115, 0.4440sec\n",
            "epoch: 92, loss_train: 0.3060, accuracy_train: 0.9451, loss_valid: 0.2520, accuracy_valid: 0.9108, 0.4500sec\n",
            "epoch: 93, loss_train: 0.3060, accuracy_train: 0.9458, loss_valid: 0.2518, accuracy_valid: 0.9100, 0.4450sec\n",
            "epoch: 94, loss_train: 0.3060, accuracy_train: 0.9457, loss_valid: 0.2508, accuracy_valid: 0.9115, 0.4324sec\n",
            "epoch: 95, loss_train: 0.3060, accuracy_train: 0.9472, loss_valid: 0.2517, accuracy_valid: 0.9078, 0.4288sec\n",
            "epoch: 96, loss_train: 0.3060, accuracy_train: 0.9455, loss_valid: 0.2499, accuracy_valid: 0.9108, 0.4443sec\n",
            "epoch: 97, loss_train: 0.3060, accuracy_train: 0.9469, loss_valid: 0.2495, accuracy_valid: 0.9115, 0.4339sec\n",
            "epoch: 98, loss_train: 0.3060, accuracy_train: 0.9460, loss_valid: 0.2522, accuracy_valid: 0.9085, 0.4824sec\n",
            "epoch: 99, loss_train: 0.3060, accuracy_train: 0.9457, loss_valid: 0.2548, accuracy_valid: 0.9078, 0.4608sec\n",
            "epoch: 100, loss_train: 0.3060, accuracy_train: 0.9486, loss_valid: 0.2493, accuracy_valid: 0.9093, 0.4309sec\n",
            "epoch: 101, loss_train: 0.3060, accuracy_train: 0.9485, loss_valid: 0.2488, accuracy_valid: 0.9093, 0.4375sec\n",
            "epoch: 102, loss_train: 0.3060, accuracy_train: 0.9481, loss_valid: 0.2481, accuracy_valid: 0.9100, 0.4323sec\n",
            "epoch: 103, loss_train: 0.3060, accuracy_train: 0.9487, loss_valid: 0.2500, accuracy_valid: 0.9093, 0.4415sec\n",
            "epoch: 104, loss_train: 0.3060, accuracy_train: 0.9496, loss_valid: 0.2493, accuracy_valid: 0.9123, 0.4293sec\n",
            "epoch: 105, loss_train: 0.3060, accuracy_train: 0.9494, loss_valid: 0.2488, accuracy_valid: 0.9138, 0.4531sec\n",
            "epoch: 106, loss_train: 0.3060, accuracy_train: 0.9500, loss_valid: 0.2474, accuracy_valid: 0.9145, 0.4366sec\n",
            "epoch: 107, loss_train: 0.3060, accuracy_train: 0.9502, loss_valid: 0.2471, accuracy_valid: 0.9130, 0.4356sec\n",
            "epoch: 108, loss_train: 0.3060, accuracy_train: 0.9506, loss_valid: 0.2465, accuracy_valid: 0.9130, 0.4328sec\n",
            "epoch: 109, loss_train: 0.3060, accuracy_train: 0.9515, loss_valid: 0.2474, accuracy_valid: 0.9130, 0.4271sec\n",
            "epoch: 110, loss_train: 0.3060, accuracy_train: 0.9505, loss_valid: 0.2482, accuracy_valid: 0.9153, 0.4572sec\n",
            "epoch: 111, loss_train: 0.3060, accuracy_train: 0.9520, loss_valid: 0.2476, accuracy_valid: 0.9130, 0.4580sec\n",
            "epoch: 112, loss_train: 0.3060, accuracy_train: 0.9512, loss_valid: 0.2476, accuracy_valid: 0.9145, 0.4576sec\n",
            "epoch: 113, loss_train: 0.3060, accuracy_train: 0.9533, loss_valid: 0.2468, accuracy_valid: 0.9138, 0.4192sec\n",
            "epoch: 114, loss_train: 0.3060, accuracy_train: 0.9525, loss_valid: 0.2473, accuracy_valid: 0.9145, 0.4459sec\n",
            "epoch: 115, loss_train: 0.3060, accuracy_train: 0.9534, loss_valid: 0.2480, accuracy_valid: 0.9160, 0.4258sec\n",
            "epoch: 116, loss_train: 0.3060, accuracy_train: 0.9534, loss_valid: 0.2475, accuracy_valid: 0.9145, 0.4233sec\n",
            "epoch: 117, loss_train: 0.3060, accuracy_train: 0.9540, loss_valid: 0.2466, accuracy_valid: 0.9153, 0.4408sec\n",
            "epoch: 118, loss_train: 0.3060, accuracy_train: 0.9531, loss_valid: 0.2468, accuracy_valid: 0.9153, 0.4354sec\n",
            "epoch: 119, loss_train: 0.3060, accuracy_train: 0.9553, loss_valid: 0.2480, accuracy_valid: 0.9153, 0.4527sec\n",
            "epoch: 120, loss_train: 0.3060, accuracy_train: 0.9545, loss_valid: 0.2481, accuracy_valid: 0.9138, 0.4442sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(model, loader, device):\n",
        "  model.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in loader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      pred = torch.argmax(outputs, dim=-1)\n",
        "      total += len(inputs)\n",
        "      correct += (pred == labels).sum().item()\n",
        "      \n",
        "  return correct / total"
      ],
      "metadata": {
        "id": "RMP0hWjHqnwB"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_train = calculate_accuracy(model, dataloader_train, device)\n",
        "acc_test = calculate_accuracy(model, dataloader_test, device)\n",
        "print(f'train accuracy_score：{acc_train:.3f}')\n",
        "print(f'test accuracy_score：{acc_test:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thbmOZ2-qeQs",
        "outputId": "9e9cce4a-614b-46f7-d3d1-aeabf60e5d7b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train accuracy_score：0.954\n",
            "test accuracy_score：0.915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "03AMabAzqlIT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}