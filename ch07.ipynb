{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsutsumi-ozro/NLP-100knocks/blob/main/ch07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "無料ColabではRAMに限界があり実行できず.<br>"
      ],
      "metadata": {
        "id": "_LIT6LZrkyuc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsXTwoh9IVfU"
      },
      "source": [
        "## 第7章: 単語ベクトル\n",
        "単語の意味を実ベクトルで表現する単語ベクトル（単語埋め込み）に関して，以下の処理を行うプログラムを作成せよ．"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "基本的にわからない可能性が高いので、解答を写経&document熟読の方針<br>\n",
        "[使用する解答](https://amaru-ai.com/entry/2022/10/13/200754)"
      ],
      "metadata": {
        "id": "jmDLvUzSImHn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEXpKyPQIVfV"
      },
      "source": [
        "### 60. 単語ベクトルの読み込みと表示\n",
        "Google Newsデータセット（約1,000億単語）での[学習済み単語ベクトル](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing)（300万単語・フレーズ，300次元）をダウンロードし，”United States”の単語ベクトルを表示せよ．ただし，”United States”は内部的には”United_States”と表現されていることに注意せよ．\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gdownはpythonスクリプト内でGoogleDriveからファイルをダウンロードすることができるらしい. 便利そう."
      ],
      "metadata": {
        "id": "8MPP13vyePnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> googledriveのやつが使えなってるらしいので、違うところからダウンロードする必要あり<br>\n",
        "> 参考：https://ja.stackoverflow.com/questions/78347/not-a-gzipped-file-b%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC<br>\n",
        "\n",
        "ちなみに上のリンクの解答urlでも上手く動かなかった"
      ],
      "metadata": {
        "id": "LtHcKt8nfAZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import gdown\n",
        "url = 'https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing'\n",
        "output = 'GoogleNews-vectors-negative300.bin.gz'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "5BF73ar2dvHt",
        "outputId": "be9f0dbc-4c3a-4966-aaed-4161c9deb47c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gdown/parse_url.py:35: UserWarning: You specified a Google Drive link that is not the correct link to download a file. You might want to try `--fuzzy` option or the following url: https://drive.google.com/uc?id=None\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "71.2kB [00:00, 8.32MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GoogleNews-vectors-negative300.bin.gz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FILE_ID = \"0B7XkCwpI5KDYNlNUTTlSS21pQmM\"<br>\n",
        "FILE_NAME = \"GoogleNews-vectors-negative300.bin.gz\"<br>\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$FILE_ID\" -O $FILE_NAME && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "Y0Gi_3Mba_q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#FILE_ID = \"0B7XkCwpI5KDYNlNUTTlSS21pQmM\"\n",
        "#FILE_NAME = \"GoogleNews-vectors-negative300.bin.gz\"\n",
        "#!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$FILE_ID\" -O $FILE_NAME && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2b46I_EgsTj",
        "outputId": "baee9c67-2a57-4a87-ae10-afbc2f686467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-05 05:58:59--  https://docs.google.com/uc?export=download&confirm=&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.142.101, 74.125.142.113, 74.125.142.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.142.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0g-8s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kddkb17s0tb8b7h6nevndd8oa2skielo/1672898325000/06848720943842814915/*/0B7XkCwpI5KDYNlNUTTlSS21pQmM?e=download&uuid=6f46dcc7-4d15-4b60-be41-8ee0ecab7e97 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-01-05 05:58:59--  https://doc-0g-8s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kddkb17s0tb8b7h6nevndd8oa2skielo/1672898325000/06848720943842814915/*/0B7XkCwpI5KDYNlNUTTlSS21pQmM?e=download&uuid=6f46dcc7-4d15-4b60-be41-8ee0ecab7e97\n",
            "Resolving doc-0g-8s-docs.googleusercontent.com (doc-0g-8s-docs.googleusercontent.com)... 172.253.117.132, 2607:f8b0:400e:c0a::84\n",
            "Connecting to doc-0g-8s-docs.googleusercontent.com (doc-0g-8s-docs.googleusercontent.com)|172.253.117.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  68.4MB/s    in 18s     \n",
            "\n",
            "2023-01-05 05:59:17 (89.2 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gensimのdocument読みづらい&検索遅いでキレそう<br>\n",
        "一生Searching...なんだが"
      ],
      "metadata": {
        "id": "B75TrP9ggr6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format('/content/GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "metadata": {
        "id": "nC7mYpuOea1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model['United_States']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz3WWj56h-If",
        "outputId": "88b4554f-0112-40dc-ac98-c195a255c505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.61328125e-02, -4.83398438e-02,  2.35351562e-01,  1.74804688e-01,\n",
              "       -1.46484375e-01, -7.42187500e-02, -1.01562500e-01, -7.71484375e-02,\n",
              "        1.09375000e-01, -5.71289062e-02, -1.48437500e-01, -6.00585938e-02,\n",
              "        1.74804688e-01, -7.71484375e-02,  2.58789062e-02, -7.66601562e-02,\n",
              "       -3.80859375e-02,  1.35742188e-01,  3.75976562e-02, -4.19921875e-02,\n",
              "       -3.56445312e-02,  5.34667969e-02,  3.68118286e-04, -1.66992188e-01,\n",
              "       -1.17187500e-01,  1.41601562e-01, -1.69921875e-01, -6.49414062e-02,\n",
              "       -1.66992188e-01,  1.00585938e-01,  1.15722656e-01, -2.18750000e-01,\n",
              "       -9.86328125e-02, -2.56347656e-02,  1.23046875e-01, -3.54003906e-02,\n",
              "       -1.58203125e-01, -1.60156250e-01,  2.94189453e-02,  8.15429688e-02,\n",
              "        6.88476562e-02,  1.87500000e-01,  6.49414062e-02,  1.15234375e-01,\n",
              "       -2.27050781e-02,  3.32031250e-01, -3.27148438e-02,  1.77734375e-01,\n",
              "       -2.08007812e-01,  4.54101562e-02, -1.23901367e-02,  1.19628906e-01,\n",
              "        7.44628906e-03, -9.03320312e-03,  1.14257812e-01,  1.69921875e-01,\n",
              "       -2.38281250e-01, -2.79541016e-02, -1.21093750e-01,  2.47802734e-02,\n",
              "        7.71484375e-02, -2.81982422e-02, -4.71191406e-02,  1.78222656e-02,\n",
              "       -1.23046875e-01, -5.32226562e-02,  2.68554688e-02, -3.11279297e-02,\n",
              "       -5.59082031e-02, -5.00488281e-02, -3.73535156e-02,  1.25976562e-01,\n",
              "        5.61523438e-02,  1.51367188e-01,  4.29687500e-02, -2.08007812e-01,\n",
              "       -4.78515625e-02,  2.78320312e-02,  1.81640625e-01,  2.20703125e-01,\n",
              "       -3.61328125e-02, -8.39843750e-02, -3.69548798e-05, -9.52148438e-02,\n",
              "       -1.25000000e-01, -1.95312500e-01, -1.50390625e-01, -4.15039062e-02,\n",
              "        1.31835938e-01,  1.17675781e-01,  1.91650391e-02,  5.51757812e-02,\n",
              "       -9.42382812e-02, -1.08886719e-01,  7.32421875e-02, -1.15234375e-01,\n",
              "        8.93554688e-02, -1.40625000e-01,  1.45507812e-01,  4.49218750e-02,\n",
              "       -1.10473633e-02, -1.62353516e-02,  4.05883789e-03,  3.75976562e-02,\n",
              "       -6.98242188e-02, -5.46875000e-02,  2.17285156e-02, -9.47265625e-02,\n",
              "        4.24804688e-02,  1.81884766e-02, -1.73339844e-02,  4.63867188e-02,\n",
              "       -1.42578125e-01,  1.99218750e-01,  1.10839844e-01,  2.58789062e-02,\n",
              "       -7.08007812e-02, -5.54199219e-02,  3.45703125e-01,  1.61132812e-01,\n",
              "       -2.44140625e-01, -2.59765625e-01, -9.71679688e-02,  8.00781250e-02,\n",
              "       -8.78906250e-02, -7.22656250e-02,  1.42578125e-01, -8.54492188e-02,\n",
              "       -3.18359375e-01,  8.30078125e-02,  6.34765625e-02,  1.64062500e-01,\n",
              "       -1.92382812e-01, -1.17675781e-01, -5.41992188e-02, -1.56250000e-01,\n",
              "       -1.21582031e-01, -4.95605469e-02,  1.20117188e-01, -3.83300781e-02,\n",
              "        5.51757812e-02, -8.97216797e-03,  4.32128906e-02,  6.93359375e-02,\n",
              "        8.93554688e-02,  2.53906250e-01,  1.65039062e-01,  1.64062500e-01,\n",
              "       -1.41601562e-01,  4.58984375e-02,  1.97265625e-01, -8.98437500e-02,\n",
              "        3.90625000e-02, -1.51367188e-01, -8.60595703e-03, -1.17675781e-01,\n",
              "       -1.97265625e-01, -1.12792969e-01,  1.29882812e-01,  1.96289062e-01,\n",
              "        1.56402588e-03,  3.93066406e-02,  2.17773438e-01, -1.43554688e-01,\n",
              "        6.03027344e-02, -1.35742188e-01,  1.16210938e-01, -1.59912109e-02,\n",
              "        2.79296875e-01,  1.46484375e-01, -1.19628906e-01,  1.76757812e-01,\n",
              "        1.28906250e-01, -1.49414062e-01,  6.93359375e-02, -1.72851562e-01,\n",
              "        9.22851562e-02,  1.33056641e-02, -2.00195312e-01, -9.76562500e-02,\n",
              "       -1.65039062e-01, -2.46093750e-01, -2.35595703e-02, -2.11914062e-01,\n",
              "        1.84570312e-01, -1.85546875e-02,  2.16796875e-01,  5.05371094e-02,\n",
              "        2.02636719e-02,  4.25781250e-01,  1.28906250e-01, -2.77099609e-02,\n",
              "        1.29882812e-01, -1.15722656e-01, -2.05078125e-02,  1.49414062e-01,\n",
              "        7.81250000e-03, -2.05078125e-01, -8.05664062e-02, -2.67578125e-01,\n",
              "       -2.29492188e-02, -8.20312500e-02,  8.64257812e-02,  7.61718750e-02,\n",
              "       -3.66210938e-02,  5.22460938e-02, -1.22070312e-01, -1.44042969e-02,\n",
              "       -2.69531250e-01,  8.44726562e-02, -2.52685547e-02, -2.96630859e-02,\n",
              "       -1.68945312e-01,  1.93359375e-01, -1.08398438e-01,  1.94091797e-02,\n",
              "       -1.80664062e-01,  1.93359375e-01, -7.08007812e-02,  5.85937500e-02,\n",
              "       -1.01562500e-01, -1.31835938e-01,  7.51953125e-02, -7.66601562e-02,\n",
              "        3.37219238e-03, -8.59375000e-02,  1.25000000e-01,  2.92968750e-02,\n",
              "        1.70898438e-01, -9.37500000e-02, -1.09375000e-01, -2.50244141e-02,\n",
              "        2.11914062e-01, -4.44335938e-02,  6.12792969e-02,  2.62451172e-02,\n",
              "       -1.77734375e-01,  1.23046875e-01, -7.42187500e-02, -1.67968750e-01,\n",
              "       -1.08886719e-01, -9.04083252e-04, -7.37304688e-02,  5.49316406e-02,\n",
              "        6.03027344e-02,  8.39843750e-02,  9.17968750e-02, -1.32812500e-01,\n",
              "        1.22070312e-01, -8.78906250e-03,  1.19140625e-01, -1.94335938e-01,\n",
              "       -6.64062500e-02, -2.07031250e-01,  7.37304688e-02,  8.93554688e-02,\n",
              "        1.81884766e-02, -1.20605469e-01, -2.61230469e-02,  2.67333984e-02,\n",
              "        7.76367188e-02, -8.30078125e-02,  6.78710938e-02, -3.54003906e-02,\n",
              "        3.10546875e-01, -2.42919922e-02, -1.41601562e-01, -2.08007812e-01,\n",
              "       -4.57763672e-03, -6.54296875e-02, -4.95605469e-02,  2.22656250e-01,\n",
              "        1.53320312e-01, -1.38671875e-01, -5.24902344e-02,  4.24804688e-02,\n",
              "       -2.38281250e-01,  1.56250000e-01,  5.83648682e-04, -1.20605469e-01,\n",
              "       -9.22851562e-02, -4.44335938e-02,  3.61328125e-02, -1.86767578e-02,\n",
              "       -8.25195312e-02, -8.25195312e-02, -4.05273438e-02,  1.19018555e-02,\n",
              "        1.69921875e-01, -2.80761719e-02,  3.03649902e-03,  9.32617188e-02,\n",
              "       -8.49609375e-02,  1.57470703e-02,  7.03125000e-02,  1.62353516e-02,\n",
              "       -2.27050781e-02,  3.51562500e-02,  2.47070312e-01, -2.67333984e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzm1qevAIVfW"
      },
      "source": [
        "### 61. 単語の類似度\n",
        "“United States”と”U.S.”のコサイン類似度を計算せよ．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.similarity('United_States', 'U.S.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZzdfRMfiM37",
        "outputId": "939fc9bb-1b78-4e56-f4f4-261741050fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.73107743"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjZVvseGIVfW"
      },
      "source": [
        "### 62. 類似度の高い単語10件\n",
        "“United States”とコサイン類似度が高い10語と，その類似度を出力せよ．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar('United_States', topn=10)"
      ],
      "metadata": {
        "id": "Tj0Z7V1TiuIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxkZ296uIVfW"
      },
      "source": [
        "### 63. 加法構成性によるアナロジー\n",
        "“Spain”の単語ベクトルから”Madrid”のベクトルを引き，”Athens”のベクトルを足したベクトルを計算し，そのベクトルと類似度の高い10語とその類似度を出力せよ．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vec = model['Spain'] - model['madrid'] + model['Athens']\n",
        "model.most_similar(positive=['Spain', 'Athens'], negative=['Madrid'], topn=10)"
      ],
      "metadata": {
        "id": "p37SPnFUjMRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkmWv3ifIVfW"
      },
      "source": [
        "### 64. アナロジーデータでの実験\n",
        "[単語アナロジーの評価データ](http://download.tensorflow.org/data/questions-words.txt)をダウンロードし，vec(2列目の単語) - vec(1列目の単語) + vec(3列目の単語)を計算し，そのベクトルと類似度が最も高い単語と，その類似度を求めよ．求めた単語と類似度は，各事例の末尾に追記せよ．\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "元のデータがどんなデータか知らないと意味わからなくなる。<br>\n",
        "解説あり->https://amaru-ai.com/entry/2022/10/13/200754"
      ],
      "metadata": {
        "id": "x0q008qcmrDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://download.tensorflow.org/data/questions-words.txt"
      ],
      "metadata": {
        "id": "cig11_Q4lCL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#こんな書き方あるんだ\n",
        "with open('./question-words.txt', 'r') as f1, open('./questions-words-add.txt', 'w') as f2:\n",
        "    for line in f1:\n",
        "        line = line.split()\n",
        "        if line[0]==':':\n",
        "            category = line[1]\n",
        "        else:\n",
        "            word, cos = model.most_similar(positive=[line[1], line[2]], negative=[line[0]], topn=1)[0]\n",
        "            f2.write(' ').join([category] + line + [word, str(cos) + '\\n'])"
      ],
      "metadata": {
        "id": "BAJS1lXTlFA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 questions-words-add.txt"
      ],
      "metadata": {
        "id": "LlAAehNilpa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjyoGx78IVfW"
      },
      "source": [
        "### 65. アナロジータスクでの正解率\n",
        "64の実行結果を用い，意味的アナロジー（semantic analogy）と文法的アナロジー（syntactic analogy）の正解率を測定せよ．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./questions-words-add.txt', 'r') as f:\n",
        "    sem_cnt = 0\n",
        "    sem_cor = 0\n",
        "    syn_cnt = 0\n",
        "    syn_cor = 0\n",
        "    for line in f:\n",
        "        line = line.split()\n",
        "        if line[0].startswith('gram'):\n",
        "            syn_cnt += 1\n",
        "            if line[4] == line[5]:\n",
        "                syn_cor += 1\n",
        "        else:\n",
        "            sem_cnt += 1\n",
        "            if line[4] == line[5]:\n",
        "                sem_cor += 1\n",
        "\n",
        "print(f'意味的アナロジー正解率: {sem_cor/sem_cnt}')\n",
        "print(f'文法的アナロジー正解率: {syn_cor/syn_cnt}')"
      ],
      "metadata": {
        "id": "3t2ntKNTmjh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edlnHZmiIVfW"
      },
      "source": [
        "### 66. WordSimilarity-353での評価\n",
        "[The WordSimilarity-353 Test Collection](http://www.gabrilovich.com/resources/data/wordsim353/wordsim353.html)の評価データをダウンロードし，単語ベクトルにより計算される類似度のランキングと，人間の類似度判定のランキングの間のスピアマン相関係数を計算せよ．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.gabrilovich.com/resources/data/wordsim353/wordsim353.zip\n",
        "!unzip wordsim353.zip\n",
        "!head -10 './combined.csv'"
      ],
      "metadata": {
        "id": "ucY3nfUtn7BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ws353 = []\n",
        "with open('./combined.csv', 'r') as f:\n",
        "    next(f)\n",
        "    for line in f:\n",
        "        line = [s.strip() for s in line.split(',')]\n",
        "        line.append(model.similarity(line[0], line[1]))\n",
        "        ws353.append(line)\n",
        "\n",
        "for i in range(5):\n",
        "    print(ws353[i])"
      ],
      "metadata": {
        "id": "MdxkTNbSn9vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://qiita.com/dacciinfo/items/88debe69f9f4e927aafc"
      ],
      "metadata": {
        "id": "u2KIPWIMpoDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "human = np.array(ws353).T[2]\n",
        "w2v = np.array(ws353).T[3]\n",
        "correlation, pvalue = spearmanr(human, w2v)\n",
        "\n",
        "print(f'スピアマン相関係数: {correlation:.3f}')"
      ],
      "metadata": {
        "id": "wtPN7VU8ohDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7yptzNGIVfX"
      },
      "source": [
        "### 67. k-meansクラスタリング\n",
        "国名に関する単語ベクトルを抽出し，k-meansクラスタリングをクラスタ数k=5として実行せよ．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#国名に関する単語ベクトルを単語アナロジーの評価データから収集\n",
        "countries = set()\n",
        "with open('./questions-words-add.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.split()\n",
        "        if line[0] in ['capital-common-countries', 'capital-world']:\n",
        "            countries.add(line[2])\n",
        "        elif line[0] in ['currency', 'gram6-nationality-adjective']:\n",
        "            countries.add(line[1])\n",
        "countries = list(countries)\n",
        "\n",
        "countries_vec = [model[country] for country in countries]"
      ],
      "metadata": {
        "id": "RAPtSLIIpslJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=5)\n",
        "kmeans.fit(countries_vec)\n",
        "for i in range(5):\n",
        "    cluster = np.where(kmeans.labels_==i)[0]\n",
        "    print('cluster', i)\n",
        "    print(', '.join([countries[k] for k in cluster]))"
      ],
      "metadata": {
        "id": "CSIE5YmLqkfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBFvr64PIVfX"
      },
      "source": [
        "### 68. Ward法によるクラスタリング\n",
        "国名に関する単語ベクトルに対し，Ward法による階層型クラスタリングを実行せよ．さらに，クラスタリング結果をデンドログラムとして可視化せよ．"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.albert2005.co.jp/knowledge/data_mining/cluster/hierarchical_clustering<br>\n",
        "計算量は多いが分類感度が良い。<br>\n",
        "https://analysis-navi.com/?p=1884"
      ],
      "metadata": {
        "id": "0jYLwQhBtTtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "Z = linkage(countries_vec, method='ward')\n",
        "dendrogram(Z, labels=countries)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XkNUXivXszR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn8BoQNcIVfX"
      },
      "source": [
        "### 69. t-SNEによる可視化\n",
        "ベクトル空間上の国名に関する単語ベクトルをt-SNEで可視化せよ．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMymW_myIVfX"
      },
      "outputs": [],
      "source": [
        "!pip install bhtsne"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bhtsne\n",
        "\n",
        "embedded = bhtsne.tsne(np.array(countries_vec).astype(np.float64), dimensions=2, rand_seed=123)\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.scatter(np.array(embedded).T[0], np.array(embedded).T[1])\n",
        "for (x, y), name in zip(embedded, countries):\n",
        "    plt.annotate(name, (x, y))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V6lTlPK7tv1I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}